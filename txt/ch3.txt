                           CHAPTER 3: USING THE SHELL



The shell --- the program that interprets your requests to run programs --- is
the most important program for most UNIX users; with the possible exception of
your favorite text editor, you will spend more time working with the shell than
any other program. In this chapter and in Chapter 5, we will spend a fair amount
of time on the shell's capabilities. The main point we want to make is that you
can accomplish a lot without much hard work, and certainly without resorting to
programming in a conventional language like C, if you know how to use the shell.

We have divided our coverage of the shell into two chapters. This chapter goes
one step beyond the necessities covered in Chapter 1 to some fancier but
commonly used shell features, such as metacharacters, quoting, creating new
commands, passing arguments to them, the use of shell variables, and some
elementary control flow. These are topics you should know for your own use of
the shell. The material in Chapter 5 is heavier going --- it is intended for
writing serious shell programs, ones that are bullet-proofed for use by
others. The division between the two chapters is somewhat arbitrary, of course,
so both should be read eventually.



3.1 Command line structure 

To proceed, we need a slightly better understanding of just what a command is,
and how it is interpreted by the shell. This section is more formal coverage,
with some new information, of the shell basics introduced in the first chapter.

The simplest command is a single word, usually naming a file for execution
(later we will see some other types of commands):

        $ who                          Execute the file /bin/who 
        you      tty2    Sep 28 07:51 
        jpl      tty4    Sep 28 08:32 
        $ 

A command usually ends with a new line, but semicolon ; is also a command
terminator:

        $ date
        Wed Sep 28 09:07:23 EDT 1983
        $ date; who
        Wed Sep 28 09:07:23 EDT 1983
        you      tty2    Sep 28 07:51
        jpl      tty4    Sep 28 08:32
        $ 

Although semicolons can be used to terminate commands, as usual nothing happens
until you type RETURN. Notice that the shell only prints one prompt after
multiple commands, but except for the prompt,

        $ date; who

is identical to typing the two commands on different lines. In particular, who
doesn't run until date has finished.

Try sending the output of "date; who" through a pipe:

        $ date; who | wc
        Wed Sep 28 09:08:48 EDT 1983
              2     10     60
        $ 

This might not be what you expected, because only the output of who goes to
wc. Connecting who and wc with a pipe forms a single command, called a pipeline,
that runs after date. The precedence of | is higher than that of ';' as the
shell parses the command line.

Parentheses can be used to group commands:

        $ (date; who)
        Wed Sep 28 09:11:09 EDT 1983
        you      tty2    Sep 28 07:51
        jpl      tty4    Sep 28 08:32
        $ (date; who) | wc
              3     16      89
        $ 

The output of date and who are concatenated into a single stream that can be
sent down a pipe.

Data flowing through a pipe can be tapped and placed in a file (but not another
pipe) with the tee command, which is not part of the shell, but is nonetheless
handy for manipulating pipes. One use is to save intermediate output int a file:

        $ (date; who) | tee save | wc
              3     16     89                       output from wc
        $ cat save
        Wed Sep 28 09:13:22 EDT 1983
        you      tty2    Sep 28 07:51
        jpl      tty4    Sep 28 08:32
        $ wc <save
              3     16     89
        $   

tee copies its input to the named file or files, as well as to its output, so wc
receives the same date as if tee weren't in the pipeline.

Another command terminator is the ampersand &. It's exactly like the semicolon
or newline, except that it tells the shell not to wait for the command to
complete. Typically, & is used to run a long-running command "in the background"
while you continue to type interactive commands:

        $ long-running-command &
        5273                            Process-id of long-running-command
        $                               Prompt appears immediately

Given the ability to group commands, there are some more interesting uses of
background processes. The command sleep waits the specified number of seconds
before exiting.

        $ sleep 5
        $                               Five seconds pass before prompt
        $ (sleep 5; date) & date
        5278
        Wed Sep 28 09:18:20 EDT 1983    Output from second date
        $ Wed Sep 28 09:18:25 EDT 1983  Prompt appears, then date 5 etc. later

The background process starts but immediately sleeps; meanwhile, the second date
command prints the current time and the shell prompts for a new command. Five
seconds later, the sleep exits and the first date prints the new time. It's hard
to represent the passage of time on paper, so you should try this
example. (Depending on how busy your machine is and other such details, the
difference between the two times might not be exactly five seconds.) This is an
easy way to run a command in the future; consider

        $ (sleep 300; echo Tea is ready) &     Tea will be ready in 5 minutes
        5291
        $

as a handy reminder mechanism. (A ctl-g in the string to be echoed will ring the
terminal's bell when it's printed.) The parentheses are needed in these
examples, since the precedence of & is higher than that of ';'.

The & terminator applies to the commands, and since pipelines are commands you
don't need parentheses to run pipelines in the background:

        $ pr file | lpr &

arranges to print the file on the line printer without making you wait for the
command to finish. Parenthesizing the pipeline has the same effect, but requires
more typing:

        $ (pr file | lpr) &                     Same as last example

Most programs accept arguments on the command line, such as file (an argument to
pr) in the above example. Arguments are words, separated by blanks and tabs,
that typically name files to be processed by the command, but they are strings
that may be interpreted any way the program sees fit. For example, pr accepts
names of the files to print, echo echoes its arguments without interpretation,
and grep's first argument specifies a text pattern to search for. And, of
course, most programs also have options, indicated by arguments beginning with
a minus sign.

The various special characters interpreted by the shell, such as <, >, |, ; and
&, are not arguments to the programs the shell runs. They instead control how
the shell runs them. For example,

        $ echo Hello >junk

tells the shell to run echo with the single argument Hello, and place the output
in the file junk. The string >junk is not an argument to echo; it is interpreted
by the shell and never seen by echo. In fact, it need not be the last string in
the command:

        $ >junk echo hello

is identical, but less obvious.


Exercise 3-1 What are the differences among the following three commands?

    $ cat file | pr
    $ pr <file
    $ pr file

(Over the years the redirection operator < has lost some ground to pipes; people
seem to fine "cat file |" more natural than "<file".)


Metacharacters

The shell recognizes a number of other characters as special; the most commonly
used is the asterisk * which tells the shell to search the directory for
filenames in which any string of characters occurs in the position of the *. For
example,

        $ echo *

is a poor facsimile of ls. Something we didn't mention in Chapter 1 is that the
filename-matching characters do not look at filenames beginning with a dot, to
avoid problems with the names '.' and '..' that are in every directory. The rule
is: the filename-matching characters only match filenames beginning with a
period if the period is explicitly supplied in the pattern. As usual, a
judicious echo or two will clarify what happens:

        $ ls
        .profile
        junk
        temp
        $ echo *
        junk temp
        $ echo .*
        . .. .profile
        $

Characters like * that have special properties are known as
metacharacters. There are a lot of them: Table 3.1 in the complete list,
although a few of them won't be discussed until Chapter 5.

+------------------------------------------------------------------------------+
|                         Table 3.1: Shell Metacharacters                      |
|                                                                              |
| >            prog >file direct standard output to file                       |
| >>           prog >>file append standard output to file                      |
| <            prog <file take standard input from file                        |
| |            p1|p2 connect standard output of p1 to standard input of p2     |
| <<str        here document: standard input follows, up to next str           |
|                on a line by itself                                           |
| *            match any string of zero or more characters in filenames        |
| ?            match any single character in filenames                         |
| [ccc]        match any single character from ccc in filenames;               |
|                ranges like 0-9 or a-z are legal                              |
| ;            command terminator: p1;p2 does p1, then p2                      |
| &            like ; but doesn't wait for p1 to finish                        |
| `...`        run command(s) in ...; output replaces `...`                    |
| (...)        run command(s) in ... in a sub-shell                            |
| {...}        run command(s) in ... in current shell (rarely used)            |
| $1, $2 etc.  $0...$9 replaced by arguments to shell file                     |
| $var         value of shell variable var                                     |
| ${var}       value of var; avoids confusion when concatenated with text;     |
|                see also Table 5.3                                            |
| \            \c take character c literally, \newline discarded               |
| '...'        take ... literally                                              |
| "..."        take ... literally after $, `...` and \ interpreted             |
| #            if # starts word, rest of the line is a comment (not in 7th Ed.)|
| var=value    assign to variable var                                          |
| p1 && p2     run p1; if successful, run p2                                   |
| p1 || p2     run p1; if unsuccessful, run p2                                 |
+------------------------------------------------------------------------------+

Given the number of shell metacharacters, there has to be some way to say to the
shell, "Leave it alone." The easiest and best way to protect special characters
from being interpreted is to enclose them in single quote characters:

        $ echo '***'
        ***
        $

It's also possible to use the double quotes "...", but the shell actually peeks
inside these quotes to look for $, `...`, and \, so don't use "..." unless you
intend some processing of the quoted string.

A third possibility is to put a backslash \ in front of each character that you
want to protect from the shell, as in

        $ echo \*\*\*

Although \*\*\* isn't much like English, the shell terminology for it is still a
word, which is any single string the shell accepts as a unit, including blanks
if they are quoted.

Quotes of one kind protect quotes of the other kind:

        $ echo "Don't do that!"
        Don't do that!
        $

and they don't have to surround the whole argument:

        $ echo x'*'y
        x*y
        $ echo '*'A'?'
        *A?
        $

In this last example, because the quotes are discarded after they've done their
job, echo sees a single argument containing no quotes.

Quoted strings can contain newlines:

        $ echo 'hello
        > world'
        hello
        world
        $

The string '> ' is a secondary prompt printed by the shell when it expects you
to type more input to complete a command. In this example the quote on the first
line has to be balanced with another. The secondary prompt string is stored in
the shell variable PS2, and can be modified to taste.

In all of these examples, the quoting of a metacharacter prevents the shell from
trying to interpret it. The command

        $ echo x*y

echoes all the filenames beginning x and ending with y. As always, echo knows
nothing about files or shell metacharacters; the interpretation of *, if any, is
supplied by the shell.

What happens if no files match the pattern? The shell, rather than complaining
(as it did in early versions), passes the string on as though it had been
quoted. It's usually a bad idea to depend on this behavior, but it can be
exploited to learn of the existence of files matching a pattern:

        $ ls x*y                        Message from ls: no such files exist
        x*y not found                   Create xyzzy
        $ >xyzzy
        $ ls x*y                        File xyzzy matches x*y
        xyzzy
        $ ls 'x*y'
        x*y not found                   ls doesn't interpret the *
        $

A backslash at the end of a line causes the line to be continued; this is the
way to present a very long line to the shell.

        $ echo abc\
        > def\
        > ghi
        abcdefghi
        $

Notice that the newline is discarded when preceded b backslash, but is retained
when it appears in quotes.

The metacharacter # is almost universally used for shell commands; if a shell
word begins with #, the rest of the lines is ignored:

        $ echo hello # there
        hello
        $ echo hello#there
        hello#there
        $

The # was not part of the original 7th Edition, but it has been adopted very
widely, and we will use it in the rest of the book.


Exercise 3-2. Explain the output produced by

        $ ls .*


A digression on echo

Even though it isn't explicitly asked for, a final newline is provided by
echo. A sensible and perhaps cleaner design for echo would be to print only what
is requested. This would make it easy to issue prompts from the shell:

        $ pure-echo Enter a command:
        Enter a command:                        No trailing newline

but has the disadvantage that the most common case --- providing a newline ---
is not the default and takes extra typing:

        $ pure-echo 'Hello!
        > '
        Hello!
        $

Since a command should by default execute its most commonly used function, the
real echo appends the final newline automatically.

But what if it isn't desired? The 7th Edition echo has a single option, -n, to
suppress the last newline:

        $ echo -n Enter a command:
        Enter a command:$                       Prompt on same line
        $ echo -
        -                                       Only -n is special
        $

The only tricky case is echoing -n followed by a newline:

        $ echo -n '-n
        > '
        -n
        $

It's ugly, but it works, and this is a rare situation anyway.

A different approach, take in System V, is for echo to interpret C-like
backslash sequences, such as \b for backspace and \c (which isn't actually in
the C language) to suppress the last newline:

        $ echo 'Enter a command:\c'             System V version
        'Enter a command:$

Although this mechanism avoids confusion about echoing a minus sign, it has
other problems. echo is often used as a diagnostic aid, and backslashes are
interpreted by so many programs that having echo look at them too just adds to
the confusion.

Still, both designs of echo have good and bad points. We shall use the 7th
Edition version (-n), so if your local echo obeys a different convention, a
couple of our programs will need minor revision.

Another question of philosophy is what echo should do if given no arguments ---
specifically, should it print a blank line or nothing at all? All the current
echo implementations we know print a blank line, but past versions didn't, and
there were once great debates on the subject. Doug McIlroy imparted the right
feelings of mysticism in his discussion of the topic:


                             The UNIX and the Echo

There dwelt in the land of New Jersey the UNIX, a fair maid who savants traveled
far to admire. Dazzled by her purity, all sought to espouse her, one for her
virginal grace, another for her polished civility, yet another for her agility
in performing exacting tasks seldom accomplished even much richer land. So large
of heart and accommodating of nature was she that the UNIX adopted all but the
most insufficiently rich of her suitors. Soon many offspring grew and prospered
and spread to the ends of the earth.

Nature herself smiled and answered to the UNIX more eagerly than to other mortal
beings. Humbler folk, who knew little of more courtly manners, delighted in her
echo, so precise and crystal clear they scarce believed she could be answered by
the same rocks and woods that so garbled their own shouts into the
wilderness. And the compliant UNIX obliged with perfect echoes of whatever she
was asked.

When one impatient swain asked the UNIX, 'Echo nothing,' the UNIX obligingly
opened her mouth, echoed nothing, and closed it again.

'Whatever do you mean,' The youth demanded, 'opening your mouth like that?
Henceforth never open your mouth when you are supposed to echo nothing!' And the
UNIX obliged.

'But I want a perfect performance, even when you echo nothing,' pleaded a
sensitive youth,' and no perfect echoes can come from a closed mouth.' not
wishing to offend either one, the UNIX agreed to say different nothings for the
impatient youth and the sensitive youth. She called the sensitive nothing '\n.'

Yet now when she said '\n,' she was really not saying nothing so she had to open
her mouth twice, once to say '\n,' and once to say nothing, and so she did not
please the sensitive youth, who said forthwith, 'The \n sounds like a perfect
nothing to me, but the second one ruins it. I want you to take back one of
them.' So the UNIX, who could not abide offending, agreed to undo some echoes,
and called that '\c.' Now the sensitive youth could hear a perfect echo of
nothing by asking for '\n' and '\c' together. But they say that he died of a
surfeit of notation before he ever heard one.


Exercise 3-3. Predict what each of the following grep commands will do, then
verify your understanding.

        grep \$                 grep \\
        grep \\$                grep \\\\
        grep \\\$               grep "\$"
        grep '\$'               grep '"$'
        grep '\'$'              grep "$"

A file containing these commands themselves makes a good test case if you want
to experiment.

Exercise 3-4. How do you tell grep to search for a pattern beginning with a '-'?
Why doesn't quoting the argument help? Hint: investigate the -e option.

Exercise 3-5. Consider

        $ echo */*

Does this produce all names in all directories? In what order do the names
appear?

Exercise 3-6. (Trick question) How do you get a / into a filename (i.e., a /
that doesn't separate components of the path)?

Exercise 3-7. What happens with

        $ cat x y >y

and with

        $ cat x >>x

Think before rushing off to try them.

Exercise 3-8. If you type

        $ rm *

why can't rm warn you that you're about to delete all your files?



3.3 Creating new commands

It's now time to move on to something that we promised in Chapter 1 --- how to
create new commands out of old ones.

Given a sequence of commands that is to be repeated more than a few times, it
would be convenient to make it into a "new" command with its own name, so you
can use it like a regular command. To be specific, suppose you intend to count
users frequently with the pipeline

        $ who | wc -l

that was mentioned in Chapter 1, and you want to make a new program nu to do
that.

The first step is to create an ordinary file that contains 'who | wc -l'. You
can use a favorite editor, of you can get creative:

        $ echo 'who | wc -l' >nu

(Without the quotes, what would appear in nu?)

As we said in Chapter 1, the shell is a program just like an editor or who or
wc; its name is sh. And since it's a program, you can run it and redirect its
input. So run the shell with its input coming from the file nu instead of the
terminal:

        $ who
        you      tty2    Sep 28 07:51
        rhh      tty4    Sep 28 10:02
        moh      tty5    Sep 28 09:38
        ava      tty6    Sep 28 10:17
        $ cat nu
        who | wc -l
        $ sh <nu
              4
        $

The output is the same as it would have been if you had typed who | wc -l at the
terminal.

Again like most other programs, the shell takes its input from a file if one is
named as an argument; you could have written

        $ sh nu

for the same result. But it's a nuisance to have to type "sh" in either case:
it's longer, and it creates a distinction between programs written in, say, C
and ones written by connecting programs with the shell[1]. Therefore, if a file
is executable and if it contains text, then the shell assumes it to be a file or
shell commands. Such a file is called a shell file. All you have to do is to
make nu executable, once:

        $ chmod +x nu

and thereafter you can invoke it with

        $ nu

From now on, users from nu cannot tell, just by running it, that you implemented
it in this easy way.

The way the shell actually runs nu is to create a new shell process exactly as
if you had typed

        $ sh nu

This child shell is called a sub-shell --- a shell process invoked by your
current shell. sh nu is not the same as sh <nu, because its standard input still
connected to the terminal.

As it stands, nu works only if it's in your current directory (provided, of
course, that the current directory is in your PATH, which we will assume from
now on). To make nu part of your repertoire regardless of what directory you're
in, move it to your private bin directory, and add /usr/you/bin to your search
path:

        $ pwd
        /usr/you
        $ mkdir bin                     Make a bin if you haven't already
        $ echo $PATH                    Check PATH for sure
        :/usr/you/bin:/bin:/usr/bin     Should look like this
        $ mv nu bin                     Install nu
        $ ls nu
        nu not found                    It's really gone from current directory
        $ nu
              4                         But it's found by the shell
              
        $

of course, your PATH should be set properly by your .profile, so you don't have
to reset it every time you log in.

There are other simple commands that you might create this way to tailor your
environment to your own taste. Some that we have found convenient include

* cs, which echoes the proper sequence of mysterious characters to clear the
  screen on your terminal (24 newlines is a fairly general implementation);

* what, which runs who and ps -a to tell who's logged on and what they are
  doing;

* where, which prints the identifying name of the UNIX system you're using ---
  it's handy if you use several regularly. (Setting PS1 serves a similar
  purpose.)

Exercise 3-9. Look in /bin and /usr/bin to see how many commands are actually
shell files. Can you do it with one command? Hint: file(1). How accurate are
guesses based on file length?



3.4 Command arguments and parameters

Although nu is adequate as it stands, most shell programs interpret arguments,
so that, for example, filenames and options can be specified when the program is
run.

Suppose we want to make a program called cx to change the mode of a file to
executable, so

        $ cx nu

is a shorthand for

        $ chmod +x nu

We already know almost enough to do this. We need a file called cx whose
contents are

        chmod +x filename

The only new thing we need to know is how to tell cx what the name of the file
is, since it will be different each time cx is run.

When the shell executes a file of commands, each occurrence of $1 is replaced by
the first argument, each $2 is replaced by the second argument, and so on
through $9. So if the file cx contains

        chmod +x $1

when the command

        $ cx nu

is run, the sub-shell replaces "$1" by its first argument, "nu."

Let's look at the whole sequence of operations:

        $ echo 'chmod +x $1" >cx        Create cx originally
        $ sh cx cx                      Make cx itself executable
        $ echo echo Hi, there! >hello   Make a test program
        $ hello                         Try it
        hello: cannot execute
        $ cx hello                      Make it executable
        $ hello                         Try again
        Hi, there!                      it works
        $ mv cx /usr/you/bin            Install cx
        $ rm hello                      Clean up
        $

Notice that we said

        $ sh cx cx

exactly as the shell would have automatically done if cx were already executable
and we typed

        $ cx cx

What if you want to handle more than one argument, for example to make a program
like cx handle several files at once? A crude first cut is to put nine arguments
into the shell program, as in

        chmod +x $1 $2 $3 $4 $5 $6 $7 $8 $9

(If only works up to $9, because the string $10 is parsed as "first argument,
$1, followed by a 0"!) If the user of this shell file provides fewer than nine
arguments, the missing ones are null strings; the effect is that only the
arguments that were actually provided are passed to chmod by the sub-shell. So
this implementation works, but it's obviously unclean, and it fails if more than
nine arguments are provided.

Anticipating this problem, the shell provides a shorthand $* that means "all the
arguments." The proper way to define cx, then, is

        chmod +x $*

which works regardless of how many arguments are provided.

With $* added to your repertoire, you can make some convenient shell files, such
as lc or m:

        $ cd /usr/you/bin
        $ cat lc
        # lc: count number of lines in files
        wc -l $*
        $ cat m
        # m: a concise way to type mail
        mail $*
        $

Both can sensibly be used without arguments. If there are no arguments, $* will
be null, and no arguments at all will be passed to wc or mail. With or without
arguments, the command is invoked properly:

        $ lc /usr/you/bin/*
              1 /usr/you/bin/cx
              2 /usr/you/bin/lc
              2 /usr/you/bin/m
              1 /usr/you/bin/nu
              2 /usr/you/bin/what
              1 /usr/you/bin/where
              9 total
        $ ls /usr/you/bin | lc
              6
        $

These commands and the others in this chapter are examples of personal programs,
the sort of things you write for yourself and put in your bin, but are unlikely
to make publicly available because they are too dependent on personal taste. In
Chapter 5 we will address the issues of writing shell programs suitable for
public use.

The arguments to a shell file need not be filenames. For example, consider
searching a personal telephone directory. If you have a file named
/usr/you/lib/phone-book that contains lines like

        dial-a-joke  212-976-3838
        dial-a-prayer  212-246-4200
        dial santa  212-976-3636
        dow jones report  212-976-4141

then the grep command can be used to search it. (your own lib directory is a
good place to store such personal data bases.) Since grep doesn't care about the
format of information, you can search for names, addresses, zip codes or
anything else that you like. Let's make a directory assistance program, which
we'll call 411 in honor of the telephone directory assistance number where we
live:

        $ echo 'grep $* /usr/you/lib/phone-book' >411
        $ cx 411
        $ 411 joke
        dial-a-joke  212-976-3838
        $ 411 dial
        dial-a-joke  212-976-3838
        dial-a-prayer  212-246-4200
        dial santa  212-976-3636
        $ 411 'dow jones'
        grep: can't open jones                  Something is wrong
        $

The final example is included to show a potential problem: even though dow jones
is presented to 411 as a single argument, it contains a space and is no longer
in quotes, so the sub-shell interpreting the 411 command converts it into two
arguments to grep: it's as if you had typed

        $ grep dow jones /usr/you/lib/phone-book

and that's obviously wrong.

One remedy relies on the way the shell treats double quotes. Although anything
quoted with '...' is inviolate, the shell looks inside "..." for $'s, \'s, and
`...`'s. So if you revise 411 to look like

        grep "$*" /usr/you/lib/phone-book

the $* will be replaced by the arguments, but it will be passed to grep as a
single argument even if it contains spaces.

        $ 411 dow jones
        dow jones report  212-976-4141
        $

By the way, you can make grep (and thus 411) case-independent with the -y
option:

        $ grep -y pattern ...

with -y, lower case letters in pattern will also match upper case letters in the
input. (This option is in 7th Edition grep, but is absent from some other
systems.)

There are fine points about command arguments that we are skipping over until
Chapter 5, but one is worth noting here. The argument $0 is the name of the
program being executed --- in cx, $0 is "cx." A novel use of $0 is in the
implementation of the programs 2, 3, 4, ..., which print their output in that
many columns:

        $ who | 2
        drh      tty0    Sep 28 21:23        cvw     tty5    Sep 28 21:09
        dmr      tty6    Sep 28 21:10        scj     tty7    Sep 28 22:11
        you      tty9    Sep 28 23:00        jlb     ttyb    Sep 28 19:58
        $

The implementations of 2, 3, ... are identical; in fact they are links to the
same file:

        $ ln 2 3; ln 2 4; ln 2 5; ln 2 6
        $ ls -li [1-9]
        167222 -rwxrwxrwx 5 you         51 Sep 28 23:21 2
        167222 -rwxrwxrwx 5 you         51 Sep 28 23:21 3
        167222 -rwxrwxrwx 5 you         51 Sep 28 23:21 4
        167222 -rwxrwxrwx 5 you         51 Sep 28 23:21 5
        167222 -rwxrwxrwx 5 you         51 Sep 28 23:21 6
        $ ls /usr/you/bin | 5
        2             3             4             411           5
        6             cx            cx            cx             nu
        what          where
        $ cat 5
        # 2, 3, ...:  print in n columns
        pr -$0 -t -l1 $*
        $

The -t option turns off the heading at the top of the page and the -ln option
sets the page length to n lines. The name of the program becomes the
number-of-columns argument to pr, so the output is printed a row at a time in
the number of columns specified by $0.


3.5 Program output as arguments

Let us turn now from command arguments within a shell file to the generation of
arguments. Certainly filename expansion from metacharacters like * is the most
common way to generate arguments (other than by providing them explicitly), but
another good way is by running a program. The output of any program can be
placed in a command line by enclosing the invocation in backquotes `...`:

        $ echo At the tone the time will be `date`
        At the tone the time will be Thu Sep 29 00:02:15 EDT 1983.
        $

A small change illustrates that `...` is interpreted inside double quotes "...":

        $ echo "At the tone
        > the time will be `date`."
        At the tone
        the time will be Thu Sep 29 00:03:07 EDT 1983.
        $

As another example, suppose you want to send mail to a list of people whose
login names are in the file mailinglist. A clumsy way to handle this is to edit
mailinglist into a suitable mail command and present it to the shell, but it's
far easier to say

        $ mail `cat mailinglist` <letter

This runs cat to produce the list of user names, and those become the arguments
to mail. (When interpreting output in backquotes as arguments, the shell treats
newlines as word separators, not command-line terminators; this subject is
discussed fully in Chapter 5.) Backquotes are easy enough to use that there's
really no need for a separate mailing-list option to the mail command.

A slightly different approach is to convert the file mailinglist from just a
list of names into a program that prints the list of names:

        $ cat mailinglist               New version
        echo don whr ejs mb
        $ cx mailinglist
        $ mailinglist
        don whr ejs mb
        $

Now mailing the letter to the people on the list becomes

        $ mail `mailinglist` <letter

With the addition of one more program, it's even possible to modify the user
list interactively. The program is called pick:

        $ pick arguments ...

presents the arguments one at a time and waits after each for a response. The
output of pick is those arguments selected by y (for "yes") responses; any other
response causes the argument to be discarded. For example,

        $ pr `pick *.c` | lpr

presents each filename that ends in .c; those selected are printed with pr and
lpr. (pick is not part of the 7th Edition, but it's so easy and useful that
we've included versions of it in Chapter 5 and 6.)

Suppose you have the second version of mailinglist. Then

        $ mail `pick \`mailinglist\`` <letter
        don? y
        whr?
        ejs?
        mb? y
        $

sends the letter to don and mb. Notice that there are nested backquotes; the
backslashes prevent the interpretation of the inner `...` during the parsing of
the outer one.


Exercise 3-10. If the backquotes are omitted in

        $ echo `echo \`date\``

what happens?

Exercise 3-11. Try

        $ `date`

and explain the result.

Exercise 3-12.

        $ grep -l pattern filenames

lists the filenames in which there was a match of pattern, but produces no other
output. Try some variations on

        $ command `grep -l pattern filenames`



3.6 Shell variables

The shell has variables, like those in most programming languages, which in
shell jargon are sometimes called parameters. String such as $1 are positional
parameters --- variables that hold the arguments to a shell file. The digit
indicates the position on the command line. We have seen other shell variables:
PATH is the list of directories to search for commands, HOME is your login
directory, and so on. Unlike variables in a regular language, the argument
variables cannot be changed; although PATH is a variable whose value is $PATH,
there is no variable 1 whose value is $1. $1 is nothing more than a compact
notation for the first argument.

Leaving positional parameters aside, shell variables can be created, accessed
and modified. For example,

        $ PATH=:/bin:/usr/bin

is an assignment that changes the search path. There must be no spaces around
the equals sign, and the assigned value must be a single word, which means it
must be quoted if it contains shell metacharacters that should not be
interpreted. The value of a variable is extracted by preceding the name by a
dollar sign:

        $ PATH=$PATH:/usr/games
        $ echo $PATH
        :/usr/you/bin:/bin:/usr/bin:/usr/games
        $ PATH=:/usr/you/bin:/bin:/usr/bin              Restore it
        $

Not all variables are special to the shell. You can create new variables by
assigning them values; traditionally, variables with special meaning are spelled
in upper case, so ordinarily names are in lower case. One of the common uses of
variables is to remember long strings such as pathnames:

        $ pwd
        /usr/you/bin
        $ dir=`pwd`                             Remember where we are
        $ cd /usr/mary/bin                      Go somewhere else
        $ ln $dir/cx .                          Use the variable in a filename
        $ ...                                   Work for a while
        $ cd $dir                               Return
        $ pwd
        /usr/you/bin
        $

The shell built-in command set displays the values of all your defined
variables. To see just one or two variables, echo is more appropriate.

        $ set
        HOME=/usr/you
        IFS=

        PATH=:/usr/you/bin:/bin/:/usr/bin
        PS1=$
        PS2=>
        dir=/usr/you/bin
        $ echo $dir
        /usr/you/bin
        $

The value of a variable is associated with the shell that creates it, and is not
automatically passed to the shell's children.

        $ x=Hello                   Create x
        $ sh                        New shell
        $ echo $x                   Newline only: x undefined in the sub-shell
        $ ctl-d                     Leave this shell
        $                           Back in original shell
        $ echo $x
        Hello                       x still defined
        $

This means that a shell file cannot change the value of a variable, because the
shell file is run by a sub-shell:

        $ echo 'x="Good bye"    Make a two-line shell file ...
        > echo $x' >setx        ... to set and print x
        $ cat setx
        x="Good Bye"
        echo $x
        $ echo $x
        Hello                   x is Hello in original shell
        $ sh setx
        Good Bye                x is Good Bye in sub-shell...
        $ echo $x
        Hello                   ...but still Hello in this shell
        $

There are times when using a shell file to change shell variables would be
useful, however. An obvious example is a file to add a new directory to your
PATH. The shell therefore provides a command '.' (dot) that executes the
commands in a file in the current shell, rather than in a sub-shell. This was
originally invented so people could conveniently re-execute their .profile files
without having to log in again, but it has other uses.

        $ cat /usr/you/bin/games
        PATH=$PATH:/usr/games                      Append /usr/games to PATH
        $ echo $PATH
        :/usr/you/bin:/bin:/usr/bin
        $ . games
        $ echo $PATH
        :/usr/you/bin:/bin:/usr/bin:/usr/games
        $

The file for the '.' command is searched for with the PATH mechanism, so it can
be placed in your bin directory.

When a file is executing with '.', it is only superficially like running a shell
file. The file is not "executed" in the usual sense of the word. Instead, the
commands in it are interpreted exactly as if you had typed them interactively
--- the standard output of the shell is temporarily redirected to come from the
file. Since the file is read but not executed, it need not have execute
permissions. Another difference is that the file does not receive command line
arguments; instead $1, $2 and the rest are empty. It would be nice if arguments
were passed, but they are not.

        $ echo 'echo $x' >echox
        $ cx echox
        $ echo $x
        Hello                       As before
        $ echox
                                    x not set in sub-shell
        $ x=Hi echox
        Hi                          Value of x passed to sub-shell
        $

(Originally, assignments anywhere in the command line were passed to the
command, but this interfered with dd(1).)

The '.' mechanism should be used to change the value of a variable permanently,
while in-line assignments should be used for temporary changes. As an example,
consider again searching /usr/games for commands, with the directory not in your
PATH:

        $ ls /usr/games | grep fort
        fortune                                      Fortune cookie command
        $ fortune
        fortune: not found
        $ echo $PATH
        :/usr/you/bin:/bin:/usr/bin                  /usr/games not in PATH
        $ PATH=/usr/games fortune
        Ring the bell; close the book; quench the candle.
        $ echo $PATH
        :/usr/you/bin:/bin:/usr/bin                  PATH unchanged
        $ cat /usr/you/bin/games
        PATH=$PATH:/usr/games                        games command still there
        $ . games
        $ fortune
        Premature optimization is the root of all evil - Knuth
        $ echo $PATH
        :/usr/you/bin:/bin:/usr/bin:/usr/games       PATH changed this time
        $

It's possible to exploit both these mechanisms in a single shell file. A
slightly different games command can be used to run a single game without
changing PATH, or can set PATH permanently to include /usr/games:

        $ cat /usr/you/bin/games
        PATH=$PATH:/usr/games $*                    Note the $*
        $ cx /usr/you/bin/games
        $ echo $PATH
        :/usr/you/bin:/bin:/usr/bin                 Doesn't have /usr/games
        $ games fortune
        I'd give my right arm to be ambidextrous.
        $ echo $PATH
        :/usr/you/bin:/bin:/usr/bin                 Still doesn't
        $ . games
        $ echo $PATH
        :/usr/you/bin:/bin:/usr/bin:/usr/games      Now it does
        $ fortune
        He who hesitates is sometimes saved.
        $

The first call to games ran the shell file in a sub-shell, where PATH was
temporarily modified to include /usr/games. The second example instead
interpreted the file in the current shell, with $* the empty string, so there
was no command on the line, and PATH was modified. Using games in these two ways
is tricky, but results in a facility that is convenient and natural to use.

When you want to make the value a variable accessible in sub-shell, the shell's
export command should be used. (You might think about why there is no way to
export the value of variable from a sub-shell to its parent.) Here is one of our
earlier examples, this time with the variable exported:

        $ x=Hello
        $ export x
        $ sh                              New shell
        $ echo $x
        Hello                             x known in sub-shell
        $ x='Good Bye'                    Change its value
        $ echo $x
        Good Bye
        $ ctl-d                           Leave this shell
        $                                 Back in original shell
        $ echo $x
        Hello                             x still Hello
        $

export has subtle semantics, but for day-to-day purposes as least, a rule of
thumb suffices: don't export temporary variables set for short-term convenient,
but always export variables you want set in all your shells and sub-shells
(including, for example, shells started with the ed's ! command). Therefore,
variables special to the shell, such as PATH and HOME, should be exported.

Exercise 3-13. Why do we always include the current directory in PATH? Where
should it be placed?



3.7 More on I/O redirection

The standard error was invented so that error messages would always appear on
the terminal:

        $ diff file1 fiel2 >diff.out
        diff: fiel2: No such file or directory
        $

It's certainly desirable that error messages work this way --- it would be most
unfortunate if they disappeared into diff.out, leaving you with the impression
that the erroneous diff command had worked properly.

Every program has three default files established when it starts, numbered by
small integers called file descriptors (which we will return to in Chapter
7). The standard input, 0, and the standard output, 1, which we are already
familiar with, are often redirected from and into files and pipes. The last,
numbered 2, is the standard error output, and normally finds its way to your
terminal.

Sometimes programs produce output on the standard error even when they work
properly. One common example is the program time, which runs a command and then
reports on the standard error how much time it took.

        $ time wc ch3.1
            931   4288   22691

        real        1.0
        user        0.4
        sys         0.4
        $
        $ time wc ch3.1 >wc.out

        real        2.0
        user        0.4
        sys         0.3
        $ time wc ch3.1 >wc.out 2>time.out
        $ cat time.out

        real        1.0
        user        0.4
        sys         0.3
        $

The construction 2>filename (no spaces are allowed between the 2 and the >)
directs the standard error output into the file; it's syntactically graceless
but it does the job. (The times produced by time are not very accurate for such
a short test as this one, but for a sequence of longer tests the numbers are
useful and reasonably trustworthy, and you might well want to save them for
further analysis; see, for example, Table 8.1.)

It is also possible to merge the two output streams:

        $ time wc ch3.1 >wc.out 2>&1
        $ cat wc.out
            931   4288   22691 ch3.1

        real        1.0
        user        0.4
        sys         0.3
        $

The notation 2>&1 tells the shell to put the standard error on the same stream
as the standard output. There is not much mnemonic value to the ampersand; it's
simply an idiom to be learned. You can also use 1>&2 to add the standard output
to the standard error:

        echo ... 1>&2

prints on the standard error. In shell files, it prevents the messages from
vanishing accidentally down a pipe or into a file.

The shell provides a mechanism so you can put the standard input for a command
along with the command, rather than in a separate file, so the shell file can be
completely self-contained. Our directory information program 411 could be
written

        $ cat 411
        grep "$*" <<End
        dial-a-joke  212-976-3838
        dial-a-prayer  212-246-4200
        dial santa  212-976-3636
        dow jones report  212-976-4141
        End
        $

The shell jargon for this construction is a here document; it means that the
input is right here instead of in a file somewhere. The << signals the
construction; the word that follows (End in our example) is used to delimit the
input, which is taken to be everything up to an occurrence of that word on a
line by itself. The shell substitutes for $, `...`, and \ in a here document,
unless some part of the word is quoted with quotes or a backslash; in that case,
the whole document is taken literally.

We'll return to here documents are the end the chapter, with a much more
interesting example.

Table 3.2 lists the various input-output redirections that the shell
understands.

+------------------------------------------------------------------------------+
|                    Table 3.2: Shell I/O Redirections                         |
|                                                                              |
| >file        direct standard output to file                                  |
| >>file       append standard output to file                                  |
| <file        take standard input from file                                   |
| p1|p2        connect standard output of program p1 to input of p2            |
| ^            obsolete synonym for |                                          |
| n>file       direct output from file descriptor n to file                    |
| n>>file      append output from file descriptor n to file                    |
| n>&m         merge output from file descriptor n with file descriptor m      |
| n<&m         merge input from file descriptor n with file descriptor m       |
| <<s          here document: take standard input until next s at              |
|                beginning of a line; substitute for $, `...`, and \           |
| <<\s         here document with no substitution                              |
| <<'s'        here document with no substitution                              |
+------------------------------------------------------------------------------+

Exercise 3-14. Compare the here-document version of 411 with the original. Which
is easier to maintain? Which is a better basis for a general service?



3.8 Looping in shell programs

The shell is actually a programming language: it has variables, loops,
decision-making, and so on. We will discuss basic looping here, and talk more
about control flow in Chapter 5. Looping over a set of filenames is very common,
and the shell's for statement is the only shell control-flow statement that you
might commonly type at the terminal rather than putting in a file for later
execution. The syntax is:

        for var in list of words
        do
                commands
        done

For example, a for statement to echo filenames one per line is just

        $ for i in *
        > do
        >       echo $i
        > done

The "i" can be any shell variable, although i is traditional. Note that the
variable's value is accessed by $i, but that the for loop refers to the variable
as i. We used * to pick up all the files in the current directory, but any other
list of arguments can be used. Normally you want to do something more
interesting than merely printing filenames. One thing we do frequently is to
compare a set of files with previous versions. For example, to compare the old
version of Chapter 2 (kept in the directory old) with the current one:

        $ ls ch2.* | 5
        ch2.1        ch2.2        ch2.3        ch2.4        ch2.5
        ch2.6        ch2.7
        $ for i in ch2.*
        > do
        >       echo $i
        >       diff -b old/$i $i
        >       echo                     Add a blank line for readability
        > done | pr -h "diff `pwd`/old `pwd`" | plr &
        3712                             Process-id
        $

We piped the output into pr and lpr just to illustrate that it's possible: the
standard output of the programs with a for goes to the standard output of the
for itself. We put a fancy heading on the output with the -h option of pr, using
two embedded calls of pwd. And we set the whole sequence running asynchronously
(&) so we wouldn't have to wait for it; the & applies to the entire loop and
pipeline.

We prefer to format a for statement as shown, but you can compress it
somewhat. The main limitations are that do and done are only recognized as
keywords when they appear after a newline or semicolon. Depending on the size of
the for, it's sometimes better to write it all on one line:

        for i in list; do commands; done

You should use the for loop for multiple commands, or where the built-in
argument processing in individual commands is not suitable. But don't use it
when the individual command will already loop over file names:

        # Poor idea:
        for i in $*
        do
                chmod +x $i
        done

is inferior to

        chmod +x $*

because the for loop executes a separate chmod for each file, which is more
expensive in computer resources. (Be sure that you understand the difference
between

        for i in *

which loops over all filenames in the current directory, and

        for i in $*

which loops over all arguments to the shell file.)

The argument list for a for most often comes from pattern matching on filenames,
but it can come from anything. It could be

        $ for i in `cat ...`

or arguments could just be typed. For example, earlier in this chapter we
created a group of programs for multi-column printing, called 2, 3, and so
on. These are just links to a single file that can be made, once the file 2 has
been written, by

        $ for i in 3 4 5 6; do ln 2 $i; done
        $

As a somewhat more interesting use of the for, we could use pick to select which
files to compare with those in the backup directory:

        $ for i in `pick ch2.*`
        > do
        >        echo $i
        >        diff old/$i $i
        > done | pr | lpr
        ch2.1? y
        ch2.2?
        ch2.3?
        ch2.4? y
        ch2.5? y
        ch2.6?
        ch2.7?
        $

It's obvious that this loop should be placed in a shell file to save typing next
time: if you've done something twice, you're likely to do it again.


Exercise 3-15. If the diff loop were placed in a shell file, would you put the
pick in the shell file? Why or why not?

Exercise 3-16. What happens if the last line of the loop above is

        > done | pr | lpr &

that is, ends with an ampersand? See if you can figure it out, then try it.



3.9 bundle: putting it all together

To give something of the flavor of how shell files develop, let's work through a
larger example. Pretend you have received mail from a friend on another machine,
say somewhere!bob[2], who would like copies of the shell files in your bin. The
simplest way to send them is by return mail, so you might start by typing

        $ cd /usr/you/bin
        $ for i in `pick *`
        > do
        >       echo ============ This is file $i ============
        >       cat $i
        > done | mail somewhere!bob
        $

But look at it from somewhere!bob's viewpoint: he's going to get a mail message
with all the files clearly demarcated, but he'll need to use an editor to break
them into their component files. The flash of insight is that a properly
constructed mail message could automatically unpack itself so the recipient
needn't do any work. That implies it should be a shell file containing both the
files and the instructions to unpack it.

A second insight is that the shell's here documents are a convenient way to
combine a command invocation and the data for the command. The rest of the job
is just getting the quotes right. Here's a working program, called bundle, that
groups the files together into a self-explanatory shell file on its standard
output:

        $ cat bundle
        # bundle: group files into distribution package
        echo '# To unbundle, sh this file'
        for i
        do
                echo "echo $i 1>&2"
                echo "cat >$i <<'End of $i'"
                cat $i
                echo "End of $i"
        done
        $

Quoting "End of $i" ensures that any shell metacharacters in the files will be
ignored.

Naturally, you should try it out before inflicting it on somewhere!bob:

        $ bundle cx lc >junk                    Make a trial bundle
        $ cat junk
        # To unbundle, sh this file
        echo cx 1>&2
        cat >cx <<'End of cx'
        chmod +x cx
        End of cx
        echo lc 1>&2
        cat >lc <<'End of lc'
        # lc: count number of lines in files
        wc -l $*
        End of lc
        $ mkdir test
        $ sh ../junk                            Tr it out
        cx
        lc
        $ ls
        cx
        lc
        $ cat cx
        chmod +x $*
        $ cat lc
        # lc: count number of lines in files
        wc -l $*                                Looks good
        $ cd ..
        $ rm junk test/*; rmdir test            Clean up
        $ pwd
        /usr/you/bin
        $ bundle `pick *` | mail somewhere!bob     Send the files

There's a problem if one of the files you're sending happens to contain a line
of the form

        End of filename

but it's a low-probability event. To make bundle utterly safe, we need a thing
or two from later chapters, but it's eminently usable and convenient as it
stands.

bundle illustrates much of the flexibility of the UNIX environment: it uses
shell loops, I/O redirection, here document and shell files, it interfaces
directly to mail, and, perhaps most interesting, it is a program that creates a
program. It's one of the prettiest shell programs we know --- a few lines of
code that do something simple, useful and elegant.


Exercise 3-17. How would you use bundle to send all the files in a directory and
its subdirectories? Hint: shell files can be recursive.

Exercise 3-18. Modify bundle so it includes with each file the information
garnered from ls -l, particularly permissions and date of last change. Contrast
the facilities of bundle with the archive program ar(1).



3-10 Why a programmable shell?

The UNIX shell isn't typical of command interpreters: although it lets you run
commands in the usual way, because it is a programming language it can
accomplish much more. It's worth a brief look at what we've seen, in part
because there's a lot of material in this chapter but more because we promised
to talk about "commonly used features" and then wrote about 30 pages of shell
programming examples. But when using the shell you write little one-line
programs all the time: a pipeline is a program, as is our"Tea is ready"
example. The shell works like that: you program it constantly, but it's so easy
and natural (once you're familiar with it) that you don't think of it as
programming.

The shell does some things, like looping, I/O redirection with < and >, and
filename expansion with *, so that no program need worry about them, and more
importantly, so that the application of these facilities is uniform across all
programs. Other features, such as shell files and pipes, are really provided by
the kernel, but the shell gives a natural syntax for creating them. They go
beyond convenience, to actually increasing the capabilities of the system.

Much of the power and convenience of the shell derives from the UNIX kernel
underneath it; for example, although the shell sets up pipes, the kernel
actually moves the data through them. The way the system treats executable files
makes it possible to write shell files so that they are run exactly like
compiled programs. The user needn't be aware that they are command files ---
they aren't invoked with a special command like RUN. Also, the shell is a
program itself, not part of the kernel, so it can be tuned, extended and used
like any other program. This idea is not unique to the UNIX system, but it has
been exploited better there than anywhere else.

In Chapter 5, we'll return to the subject of shell programming, but you should
keep in mind that whatever you're doing with the shell, you're programming it
--- that's largely why it works so well.



History and bibliographic notes

The shell has been programmable from earliest times. Originally there were
separate commands for if, goto, and labels, and the goto command operated by
scanning the input file from the beginning looking for the right label. (Because
it is not possible to re-read a pipe, it was not possible to pipe into a shell
file that had any control flow.)

The 7th Edition shell was written originally by Steve Bourne with some help and
ideas from John Mashey. It contains everything needed for programming, as we
shell see in Chapter 5. In addition, input and output are rationalized: it is
possible to redirect I/O into and out of shell programs without limit. The
parsing of filename metacharacters is also internal to this shell; it had been a
separate program in earlier versions, which had to live on very small machines.

One other major shell that you may run into (you may already be using it by
preference) is csh, the so-called "C shell" developed at Berkeley by Bill Joy by
building on the 6th Edition shell. The C shell has gone further than the Bourne
shell in the direction of helping interaction --- most notably, it provides a
history mechanism that permits shorthand repetition (perhaps with slight
editing) of previously issued commands. The syntax is also somewhat
different. But because it is based on an earlier shell, it has less of the
programming convenience; it is more an interactive interpreter than a
programming language. In particular, it is not possible to pipe into or out of
control flow constructs.

pick was invented by Tom Duff, and bundle was invented independently by Alan
Hewett and James Gosling.



                                   Footnotes

[1] Nonetheless, it is a distinction made on most other operating systems.

[2] There are several notations for remote machine addresses. The form
    machine!bob is most common. See mail(1)
